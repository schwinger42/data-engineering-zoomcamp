{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:25:59.967944Z",
     "start_time": "2025-03-06T17:25:59.960469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import multiprocessing\n",
    "print(f\"Available CPU cores: {multiprocessing.cpu_count()}\")"
   ],
   "id": "520358e5a723f171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPU cores: 10\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:25:59.985683Z",
     "start_time": "2025-03-06T17:25:59.980745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install psutil if you haven't\n",
    "# !pip install psutil\n",
    "\n",
    "import psutil\n",
    "\n",
    "def get_memory_info():\n",
    "    # Get memory information\n",
    "    mem = psutil.virtual_memory()\n",
    "\n",
    "    # Convert to GB for better readability\n",
    "    total_gb = mem.total / (1024**3)\n",
    "    available_gb = mem.available / (1024**3)\n",
    "    used_gb = mem.used / (1024**3)\n",
    "\n",
    "    print(f\"Memory Status:\")\n",
    "    print(f\"Total: {total_gb:.1f}GB\")\n",
    "    print(f\"Available: {available_gb:.1f}GB\")\n",
    "    print(f\"Used: {used_gb:.1f}GB\")\n",
    "\n",
    "    # Calculate recommended Spark memory (70% of available memory)\n",
    "    recommended_spark = (mem.available * 0.7) / (1024**3)\n",
    "    print(f\"\\nRecommended Spark driver memory: {recommended_spark:.1f}GB\")\n",
    "\n",
    "    return recommended_spark\n",
    "\n",
    "# Get recommended memory\n",
    "recommended_gb = get_memory_info()\n",
    "recommended_gb"
   ],
   "id": "e7066746417104f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Status:\n",
      "Total: 64.0GB\n",
      "Available: 19.8GB\n",
      "Used: 23.3GB\n",
      "\n",
      "Recommended Spark driver memory: 13.9GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.879110717773436"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:00.189326Z",
     "start_time": "2025-03-06T17:26:00.085112Z"
    }
   },
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:00.516653Z",
     "start_time": "2025-03-06T17:26:00.192260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/Users/schwinger42/miniforge3/envs/de-zoomcamp/lib/jvm\"\n",
    "!echo $JAVA_HOME\n",
    "!$JAVA_HOME/bin/java -version"
   ],
   "id": "f3b146da41bebbf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/schwinger42/miniforge3/envs/de-zoomcamp/lib/jvm\r\n",
      "openjdk version \"23.0.2\" 2025-01-21\r\n",
      "OpenJDK Runtime Environment Zulu23.32+11-CA (build 23.0.2+7)\r\n",
      "OpenJDK 64-Bit Server VM Zulu23.32+11-CA (build 23.0.2+7, mixed mode, sharing)\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T19:28:50.605028Z",
     "start_time": "2025-03-06T19:28:50.552783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 首先檢查 Java 版本\n",
    "import subprocess\n",
    "\n",
    "def check_java_version():\n",
    "    try:\n",
    "        result = subprocess.check_output(['java', '-version'], stderr=subprocess.STDOUT).decode()\n",
    "        print(\"當前 Java 版本信息：\")\n",
    "        print(result)\n",
    "        return result\n",
    "    except:\n",
    "        print(\"無法獲取 Java 版本信息\")\n",
    "        return None\n",
    "check_java_version()"
   ],
   "id": "3de0278d961a2e00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "當前 Java 版本信息：\n",
      "openjdk version \"23.0.2\" 2025-01-21\n",
      "OpenJDK Runtime Environment Zulu23.32+11-CA (build 23.0.2+7)\n",
      "OpenJDK 64-Bit Server VM Zulu23.32+11-CA (build 23.0.2+7, mixed mode, sharing)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'openjdk version \"23.0.2\" 2025-01-21\\nOpenJDK Runtime Environment Zulu23.32+11-CA (build 23.0.2+7)\\nOpenJDK 64-Bit Server VM Zulu23.32+11-CA (build 23.0.2+7, mixed mode, sharing)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:02.595996Z",
     "start_time": "2025-03-06T17:26:00.583625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "active_session = SparkSession.getActiveSession()\n",
    "if active_session:\n",
    "    active_session.stop()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Djava.security.manager=allow\") \\\n",
    "    .config(\"spark.hadoop.hadoop.security.authentication\", \"simple\") \\\n",
    "    .config(\"spark.hadoop.hadoop.security.authorization\", \"false\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"20\") \\\n",
    "    .config(\"spark.eventLog.gcMetrics.youngGenerationGarbageCollectors\", \"G1 Young Generation\") \\\n",
    "    .config(\"spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\", \"G1 Old Generation,G1 Concurrent GC\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Course 531\") \\\n",
    "    .getOrCreate()\n"
   ],
   "id": "4bb74c116817420",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/07 01:26:01 WARN Utils: Your hostname, BarondeMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.68.58 instead (on interface en0)\n",
      "25/03/07 01:26:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/07 01:26:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:02.603676Z",
     "start_time": "2025-03-06T17:26:02.601866Z"
    }
   },
   "cell_type": "code",
   "source": "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet",
   "id": "ff939c1f87aae9d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:03.264705Z",
     "start_time": "2025-03-06T17:26:02.608425Z"
    }
   },
   "cell_type": "code",
   "source": "!wc -l fhvhv_tripdata_2024-01.parquet",
   "id": "aafccf99aba9e8ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1899765 fhvhv_tripdata_2024-01.parquet\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:05.158619Z",
     "start_time": "2025-03-06T17:26:03.270210Z"
    }
   },
   "cell_type": "code",
   "source": "df = spark.read.parquet(\"fhvhv_tripdata_2024-01.parquet\")",
   "id": "4b624d0d1af6560",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T19:28:18.907897Z",
     "start_time": "2025-03-06T19:28:08.985121Z"
    }
   },
   "cell_type": "code",
   "source": "df.show()",
   "id": "572b83d01d1f3cd9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:==================================>                      (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|hvfhs_license_num|dispatching_base_num|originating_base_num|   request_datetime|  on_scene_datetime|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|trip_miles|trip_time|base_passenger_fare|tolls| bcf|sales_tax|congestion_surcharge|airport_fee|tips|driver_pay|shared_request_flag|shared_match_flag|access_a_ride_flag|wav_request_flag|wav_match_flag|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|           HV0003|              B03404|              B03404|2024-01-03 12:31:14|2024-01-03 12:33:17|2024-01-03 12:33:35|2024-01-03 12:52:18|         133|          14|      6.27|     1123|              26.86|  0.0|0.74|     2.38|                 0.0|        0.0| 0.0|     24.23|                  N|                N|                 N|               N|             Y|\n",
      "|           HV0003|              B03404|              B03404|2024-01-02 21:23:54|2024-01-02 21:25:31|2024-01-02 21:27:32|2024-01-02 21:33:38|         143|         239|      1.54|      366|              10.18|  0.0|0.28|      0.9|                2.75|        0.0| 0.0|       6.2|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-01 07:34:38|2024-01-01 07:41:04|2024-01-01 07:42:18|2024-01-01 08:05:21|          36|         249|      6.09|     1383|              39.61|  0.0|1.09|     3.52|                2.75|        0.0| 0.0|     23.19|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-01 01:41:09|2024-01-01 01:46:18|2024-01-01 01:46:18|2024-01-01 01:58:37|         142|         246|      1.98|      739|              28.11|  0.0|0.77|     2.49|                2.75|        0.0| 0.0|     32.05|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-04 07:47:11|2024-01-04 07:47:55|2024-01-04 07:48:20|2024-01-04 07:53:04|         186|         164|      0.46|      284|               8.24|  0.0|0.23|     0.73|                2.75|        0.0| 0.0|      8.39|                  N|                N|                 N|               N|             N|\n",
      "|           HV0005|              B03406|                NULL|2024-01-03 08:45:00|               NULL|2024-01-03 08:30:13|2024-01-03 09:21:56|         213|         143|    10.832|     3103|              41.85| 0.22|1.16|     3.73|                2.75|        0.0| 0.0|     43.77|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-04 18:23:52|2024-01-04 18:24:46|2024-01-04 18:25:41|2024-01-04 18:43:32|         186|         114|      2.16|     1071|               20.8|  0.0|0.57|     1.85|                2.75|        0.0|5.19|      13.2|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-02 21:06:21|2024-01-02 21:09:12|2024-01-02 21:09:21|2024-01-02 21:19:25|          92|          95|       2.4|      604|              10.54|  0.0|0.29|     0.94|                 0.0|        0.0| 0.0|      9.13|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-01 03:19:01|2024-01-01 03:21:55|2024-01-01 03:23:45|2024-01-01 03:35:45|          89|          97|      2.87|      720|              17.85|  0.0|0.49|     1.58|                 0.0|        0.0| 0.0|      10.8|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-04 09:31:17|2024-01-04 09:32:09|2024-01-04 09:32:55|2024-01-04 09:41:26|         145|         226|      1.45|      511|              11.62|  0.0|0.32|     1.03|                 0.0|        0.0| 0.0|      7.26|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-04 13:07:02|2024-01-04 13:08:06|2024-01-04 13:08:37|2024-01-04 13:23:42|         107|         158|      2.08|      905|              13.44|  0.0|0.37|     1.19|                0.75|        0.0| 0.0|     11.24|                  Y|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-03 17:47:40|2024-01-03 17:51:05|2024-01-03 17:51:05|2024-01-03 18:29:51|         218|         196|      9.85|     2326|              35.81|  0.0|0.98|     3.18|                 0.0|        0.0| 0.0|     34.81|                  N|                N|                 N|               N|             N|\n",
      "|           HV0005|              B03406|                NULL|2024-01-03 17:41:23|               NULL|2024-01-03 17:45:40|2024-01-03 17:56:30|         210|         150|     1.265|      650|                8.7|  0.0|0.24|     0.77|                 0.0|        0.0| 0.0|      7.84|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-04 10:09:55|2024-01-04 10:11:51|2024-01-04 10:12:00|2024-01-04 10:20:24|         143|         246|      1.77|      504|              12.71|  0.0|0.35|     1.13|                2.75|        0.0| 0.0|      7.07|                  N|                N|                 N|               N|             N|\n",
      "|           HV0005|              B03406|                NULL|2024-01-04 02:31:14|               NULL|2024-01-04 02:39:17|2024-01-04 02:44:08|          76|          76|     1.401|      291|               9.85|  0.0|0.27|     0.87|                 0.0|        0.0| 0.0|      5.47|                  N|                N|                 N|               N|             N|\n",
      "|           HV0005|              B03406|                NULL|2024-01-01 13:38:12|               NULL|2024-01-01 13:42:49|2024-01-01 13:53:58|         161|         236|     2.255|      669|              15.41|  0.0|0.42|     1.37|                2.75|        0.0| 0.0|      9.33|                  N|                N|                 N|               N|             N|\n",
      "|           HV0005|              B03406|                NULL|2024-01-03 23:28:14|               NULL|2024-01-03 23:32:28|2024-01-03 23:43:24|           7|         223|     2.482|      656|               12.3|  0.0|0.34|     1.09|                 0.0|        0.0| 0.0|      9.51|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-02 10:10:00|2024-01-02 09:54:31|2024-01-02 09:56:33|2024-01-02 10:11:14|         169|          94|      1.19|      881|               9.83|  0.0|0.27|     0.87|                 0.0|        0.0| 0.0|      9.85|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-04 19:33:29|2024-01-04 19:34:28|2024-01-04 19:35:21|2024-01-04 19:45:49|         158|         100|       1.9|      628|              16.31|  0.0|0.45|     1.45|                2.75|        0.0| 0.0|      8.41|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B03404|              B03404|2024-01-01 14:18:30|2024-01-01 14:22:09|2024-01-01 14:22:25|2024-01-01 14:33:14|         121|         130|      1.96|      649|              14.53|  0.0| 0.4|     1.29|                 0.0|        0.0| 0.0|      8.68|                  N|                N|                 N|               N|             N|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:06.839881Z",
     "start_time": "2025-03-06T17:26:06.712256Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "74866b8f2856e9c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B03404', originating_base_num='B03404', request_datetime=datetime.datetime(2024, 1, 1, 0, 21, 47), on_scene_datetime=datetime.datetime(2024, 1, 1, 0, 25, 6), pickup_datetime=datetime.datetime(2024, 1, 1, 0, 28, 8), dropoff_datetime=datetime.datetime(2024, 1, 1, 1, 5, 39), PULocationID=161, DOLocationID=158, trip_miles=2.83, trip_time=2251, base_passenger_fare=45.61, tolls=0.0, bcf=1.25, sales_tax=4.05, congestion_surcharge=2.75, airport_fee=0.0, tips=0.0, driver_pay=40.18, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B03404', originating_base_num='B03404', request_datetime=datetime.datetime(2024, 1, 1, 0, 10, 56), on_scene_datetime=datetime.datetime(2024, 1, 1, 0, 11, 8), pickup_datetime=datetime.datetime(2024, 1, 1, 0, 12, 53), dropoff_datetime=datetime.datetime(2024, 1, 1, 0, 20, 5), PULocationID=137, DOLocationID=79, trip_miles=1.57, trip_time=432, base_passenger_fare=10.05, tolls=0.0, bcf=0.28, sales_tax=0.89, congestion_surcharge=2.75, airport_fee=0.0, tips=0.0, driver_pay=6.12, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B03404', originating_base_num='B03404', request_datetime=datetime.datetime(2024, 1, 1, 0, 20, 4), on_scene_datetime=datetime.datetime(2024, 1, 1, 0, 21, 51), pickup_datetime=datetime.datetime(2024, 1, 1, 0, 23, 5), dropoff_datetime=datetime.datetime(2024, 1, 1, 0, 35, 16), PULocationID=79, DOLocationID=186, trip_miles=1.98, trip_time=731, base_passenger_fare=18.07, tolls=0.0, bcf=0.5, sales_tax=1.6, congestion_surcharge=2.75, airport_fee=0.0, tips=0.0, driver_pay=9.47, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B03404', originating_base_num='B03404', request_datetime=datetime.datetime(2024, 1, 1, 0, 35, 46), on_scene_datetime=datetime.datetime(2024, 1, 1, 0, 39, 59), pickup_datetime=datetime.datetime(2024, 1, 1, 0, 41, 4), dropoff_datetime=datetime.datetime(2024, 1, 1, 0, 56, 34), PULocationID=234, DOLocationID=148, trip_miles=1.99, trip_time=930, base_passenger_fare=17.17, tolls=0.0, bcf=0.47, sales_tax=1.52, congestion_surcharge=2.75, airport_fee=0.0, tips=0.0, driver_pay=11.35, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B03404', originating_base_num='B03404', request_datetime=datetime.datetime(2024, 1, 1, 0, 48, 19), on_scene_datetime=datetime.datetime(2024, 1, 1, 0, 56, 23), pickup_datetime=datetime.datetime(2024, 1, 1, 0, 57, 21), dropoff_datetime=datetime.datetime(2024, 1, 1, 1, 10, 2), PULocationID=148, DOLocationID=97, trip_miles=2.65, trip_time=761, base_passenger_fare=38.67, tolls=0.0, bcf=1.06, sales_tax=3.43, congestion_surcharge=2.75, airport_fee=0.0, tips=0.0, driver_pay=28.63, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:06.845414Z",
     "start_time": "2025-03-06T17:26:06.842746Z"
    }
   },
   "cell_type": "code",
   "source": "df.schema",
   "id": "69455e16f1c49bd7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('originating_base_num', StringType(), True), StructField('request_datetime', TimestampNTZType(), True), StructField('on_scene_datetime', TimestampNTZType(), True), StructField('pickup_datetime', TimestampNTZType(), True), StructField('dropoff_datetime', TimestampNTZType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('trip_miles', DoubleType(), True), StructField('trip_time', LongType(), True), StructField('base_passenger_fare', DoubleType(), True), StructField('tolls', DoubleType(), True), StructField('bcf', DoubleType(), True), StructField('sales_tax', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True), StructField('tips', DoubleType(), True), StructField('driver_pay', DoubleType(), True), StructField('shared_request_flag', StringType(), True), StructField('shared_match_flag', StringType(), True), StructField('access_a_ride_flag', StringType(), True), StructField('wav_request_flag', StringType(), True), StructField('wav_match_flag', StringType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:07.251237Z",
     "start_time": "2025-03-06T17:26:06.858092Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "6138c622a92d5493",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:08.295633Z",
     "start_time": "2025-03-06T17:26:07.256556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install --upgrade pandas pyarrow\n",
    "# !pip install fastparquet\n",
    "# turn head 100 rows into head.parquet\n",
    "df.limit(100).write.parquet(\"head.parquet\", mode=\"overwrite\")\n",
    "df_pd = pd.read_parquet(\"head.parquet\", engine=\"fastparquet\")"
   ],
   "id": "88130081595abf5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:08.312634Z",
     "start_time": "2025-03-06T17:26:08.306073Z"
    }
   },
   "cell_type": "code",
   "source": "df_pd.info()",
   "id": "73c77ebb51bb46c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   hvfhs_license_num     100 non-null    object        \n",
      " 1   dispatching_base_num  100 non-null    object        \n",
      " 2   originating_base_num  71 non-null     object        \n",
      " 3   request_datetime      100 non-null    datetime64[us]\n",
      " 4   on_scene_datetime     71 non-null     datetime64[us]\n",
      " 5   pickup_datetime       100 non-null    datetime64[us]\n",
      " 6   dropoff_datetime      100 non-null    datetime64[us]\n",
      " 7   PULocationID          100 non-null    int32         \n",
      " 8   DOLocationID          100 non-null    int32         \n",
      " 9   trip_miles            100 non-null    float64       \n",
      " 10  trip_time             100 non-null    int64         \n",
      " 11  base_passenger_fare   100 non-null    float64       \n",
      " 12  tolls                 100 non-null    float64       \n",
      " 13  bcf                   100 non-null    float64       \n",
      " 14  sales_tax             100 non-null    float64       \n",
      " 15  congestion_surcharge  100 non-null    float64       \n",
      " 16  airport_fee           100 non-null    float64       \n",
      " 17  tips                  100 non-null    float64       \n",
      " 18  driver_pay            100 non-null    float64       \n",
      " 19  shared_request_flag   100 non-null    object        \n",
      " 20  shared_match_flag     100 non-null    object        \n",
      " 21  access_a_ride_flag    100 non-null    object        \n",
      " 22  wav_request_flag      100 non-null    object        \n",
      " 23  wav_match_flag        100 non-null    object        \n",
      "dtypes: datetime64[us](4), float64(9), int32(2), int64(1), object(8)\n",
      "memory usage: 18.1+ KB\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:08.322722Z",
     "start_time": "2025-03-06T17:26:08.319849Z"
    }
   },
   "cell_type": "code",
   "source": "df_pd.dtypes",
   "id": "477c057e111c8bdf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num               object\n",
       "dispatching_base_num            object\n",
       "originating_base_num            object\n",
       "request_datetime        datetime64[us]\n",
       "on_scene_datetime       datetime64[us]\n",
       "pickup_datetime         datetime64[us]\n",
       "dropoff_datetime        datetime64[us]\n",
       "PULocationID                     int32\n",
       "DOLocationID                     int32\n",
       "trip_miles                     float64\n",
       "trip_time                        int64\n",
       "base_passenger_fare            float64\n",
       "tolls                          float64\n",
       "bcf                            float64\n",
       "sales_tax                      float64\n",
       "congestion_surcharge           float64\n",
       "airport_fee                    float64\n",
       "tips                           float64\n",
       "driver_pay                     float64\n",
       "shared_request_flag             object\n",
       "shared_match_flag               object\n",
       "access_a_ride_flag              object\n",
       "wav_request_flag                object\n",
       "wav_match_flag                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:08.348450Z",
     "start_time": "2025-03-06T17:26:08.347009Z"
    }
   },
   "cell_type": "code",
   "source": "# spark.createDataFrame(df_pd).schema",
   "id": "f948fb62d5041c9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:08.577381Z",
     "start_time": "2025-03-06T17:26:08.390018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_optimal_partitions(df, target_size_mb=128):\n",
    "    total_size_bytes = df.count() * len(df.schema.fields) # Approximate size\n",
    "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "    return max(20, int(total_size_mb / target_size_mb))\n",
    "\n",
    "num_partitions = calculate_optimal_partitions(df)\n",
    "num_partitions"
   ],
   "id": "36a79b89dcf61bed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:08.613631Z",
     "start_time": "2025-03-06T17:26:08.609663Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.repartition(20)",
   "id": "78d75ed479bc3717",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:23.149935Z",
     "start_time": "2025-03-06T17:26:08.622076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 先計算並顯示每個分區的數據分佈\n",
    "from pyspark.sql.functions import spark_partition_id\n",
    "\n",
    "# 檢查分區數據分佈\n",
    "df.groupBy(spark_partition_id()).count().orderBy('count', ascending=False).show()\n",
    "\n",
    "# 寫入時添加壓縮選項\n",
    "df = df.repartition(20)\n",
    "df.write \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"fhvhv/2024/01\")\n"
   ],
   "id": "f31e84207ccee616",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|SPARK_PARTITION_ID()| count|\n",
      "+--------------------+------+\n",
      "|                   9|983198|\n",
      "|                  11|983198|\n",
      "|                  12|983198|\n",
      "|                  14|983198|\n",
      "|                  15|983198|\n",
      "|                  16|983198|\n",
      "|                  17|983198|\n",
      "|                  10|983197|\n",
      "|                  13|983197|\n",
      "|                  18|983197|\n",
      "|                  19|983197|\n",
      "|                   0|983196|\n",
      "|                   6|983196|\n",
      "|                   1|983195|\n",
      "|                   2|983195|\n",
      "|                   4|983195|\n",
      "|                   5|983195|\n",
      "|                   7|983195|\n",
      "|                   8|983195|\n",
      "|                   3|983194|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T19:29:06.446452Z",
     "start_time": "2025-03-06T19:29:06.366910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simple test to check if Spark session is alive\n",
    "try:\n",
    "    spark.range(1).count()\n",
    "    print(\"Spark session is still active\")\n",
    "except Exception as e:\n",
    "    print(\"Spark session needs to be restarted:\", str(e))\n"
   ],
   "id": "b8b01d9a8618e830",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session is still active\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:30.383899Z",
     "start_time": "2025-03-06T17:26:23.255235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Get all current configurations\n",
    "# current_conf = spark.sparkContext.getConf().getAll()\n",
    "# for item in current_conf:\n",
    "#     print(item)\n",
    "#\n",
    "# # For specific memory-related configs\n",
    "# print(\"\\nKey Memory Configurations:\")\n",
    "# memory_configs = [\n",
    "#     \"spark.driver.memory\",\n",
    "#     \"spark.executor.memory\",\n",
    "#     \"spark.memory.offHeap.enabled\",\n",
    "#     \"spark.memory.offHeap.size\"\n",
    "# ]\n",
    "# for config in memory_configs:\n",
    "#     print(f\"{config}: {spark.conf.get(config, 'Not Set')}\")\n",
    "#\n",
    "# # Get current number of partitions\n",
    "# print(f\"\\nCurrent number of partitions: {df.rdd.getNumPartitions()}\")\n"
   ],
   "id": "6f8a10048e58645d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spark.sql.shuffle.partitions', '20')\n",
      "('spark.executor.memory', '2g')\n",
      "('spark.app.id', 'local-1741281962358')\n",
      "('spark.hadoop.hadoop.security.authentication', 'simple')\n",
      "('spark.driver.memory', '10g')\n",
      "('spark.memory.offHeap.size', '2g')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.driver.host', '192.168.68.58')\n",
      "('spark.memory.offHeap.enabled', 'true')\n",
      "('spark.driver.port', '49663')\n",
      "('spark.eventLog.gcMetrics.oldGenerationGarbageCollectors', 'G1 Old Generation,G1 Concurrent GC')\n",
      "('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Djava.security.manager=allow')\n",
      "('spark.app.submitTime', '1741281961812')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n",
      "('spark.sql.warehouse.dir', 'file:/Users/schwinger42/DataspellProjects/datatalks/data-engineering-zoomcamp/module5/spark-warehouse')\n",
      "('spark.app.name', 'Course 531')\n",
      "('spark.app.startTime', '1741281961888')\n",
      "('spark.eventLog.gcMetrics.youngGenerationGarbageCollectors', 'G1 Young Generation')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.master', 'local[*]')\n",
      "('spark.submit.pyFiles', '')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.hadoop.hadoop.security.authorization', 'false')\n",
      "('spark.ui.showConsoleProgress', 'true')\n",
      "\n",
      "Key Memory Configurations:\n",
      "spark.driver.memory: 10g\n",
      "spark.executor.memory: 2g\n",
      "spark.memory.offHeap.enabled: true\n",
      "spark.memory.offHeap.size: 2g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=======================================>                 (7 + 3) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current number of partitions: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=============================================>           (8 + 2) / 10]\r"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:30.585794Z",
     "start_time": "2025-03-06T17:26:30.392841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "def check_gc_info():\n",
    "    try:\n",
    "        # 使用 jinfo 命令查看 JVM 參數\n",
    "        java_pid = subprocess.check_output(['jps']).decode()\n",
    "        print(\"Java 進程信息：\")\n",
    "        print(java_pid)\n",
    "\n",
    "        # 使用 java -XX:+PrintFlagsFinal 來查看 GC 相關配置\n",
    "        gc_flags = subprocess.check_output(['java', '-XX:+PrintFlagsFinal', '-version'],\n",
    "                                           stderr=subprocess.STDOUT).decode()\n",
    "        print(\"\\nGC 相關配置：\")\n",
    "        # 過濾出 GC 相關的配置\n",
    "        for line in gc_flags.split('\\n'):\n",
    "            if 'GC' in line:\n",
    "                print(line)\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"執行命令失敗:\", e.output.decode())\n",
    "    except Exception as e:\n",
    "        print(\"發生錯誤:\", str(e))\n",
    "\n",
    "# 執行檢查\n",
    "check_gc_info()\n"
   ],
   "id": "b30f127f23dca62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java 進程信息：\n",
      "21701 Jps\n",
      "21557 SparkSubmit\n",
      "92731 Main\n",
      "38045 \n",
      "21021 RemoteJdbcServer\n",
      "\n",
      "\n",
      "GC 相關配置：\n",
      "    uintx AdaptiveSizeMajorGCDecayTimeScale        = 10                                        {product} {default}\n",
      "     uint ConcGCThreads                            = 2                                         {product} {ergonomic}\n",
      "     bool DisableExplicitGC                        = false                                     {product} {default}\n",
      "     bool ExplicitGCInvokesConcurrent              = false                                     {product} {default}\n",
      "     uint FullGCHeapDumpLimit                      = 0                                      {manageable} {default}\n",
      "    uintx G1MixedGCCountTarget                     = 8                                         {product} {default}\n",
      "    uintx G1PeriodicGCInterval                     = 0                                      {manageable} {default}\n",
      "     bool G1PeriodicGCInvokesConcurrent            = true                                      {product} {default}\n",
      "   double G1PeriodicGCSystemLoadThreshold          = 0.000000                               {manageable} {default}\n",
      "     uint GCCardSizeInBytes                        = 512                                       {product} {default}\n",
      "     uint GCDrainStackTargetSize                   = 64                                        {product} {default}\n",
      "     uint GCHeapFreeLimit                          = 2                                         {product} {default}\n",
      "    uintx GCPauseIntervalMillis                    = 201                                       {product} {default}\n",
      "     uint GCTimeLimit                              = 98                                        {product} {default}\n",
      "     uint GCTimeRatio                              = 12                                        {product} {default}\n",
      "     bool HeapDumpAfterFullGC                      = false                                  {manageable} {default}\n",
      "     bool HeapDumpBeforeFullGC                     = false                                  {manageable} {default}\n",
      "   size_t HeapSizePerGCThread                      = 43620760                                  {product} {default}\n",
      "    uintx MaxGCPauseMillis                         = 200                                       {product} {default}\n",
      "      int ParGCArrayScanChunk                      = 50                                        {product} {default}\n",
      "     uint ParallelGCBufferWastePct                 = 10                                        {product} {default}\n",
      "     uint ParallelGCThreads                        = 9                                         {product} {default}\n",
      "     bool PrintGC                                  = false                                     {product} {default}\n",
      "     bool PrintGCDetails                           = false                                     {product} {default}\n",
      "    ccstr ShenandoahGCHeuristics                   = adaptive                                  {product} {default}\n",
      "    ccstr ShenandoahGCMode                         = satb                                      {product} {default}\n",
      "     bool UseAdaptiveSizeDecayMajorGCCost          = true                                      {product} {default}\n",
      "     bool UseAdaptiveSizePolicyWithSystemGC        = false                                     {product} {default}\n",
      "     bool UseDynamicNumberOfGCThreads              = true                                      {product} {default}\n",
      "     bool UseG1GC                                  = true                                      {product} {ergonomic}\n",
      "     bool UseGCOverheadLimit                       = true                                      {product} {default}\n",
      "     bool UseMaximumCompactionOnSystemGC           = true                                      {product} {default}\n",
      "     bool UseParallelGC                            = false                                     {product} {default}\n",
      "     bool UseSerialGC                              = false                                     {product} {default}\n",
      "     bool UseShenandoahGC                          = false                                     {product} {default}\n",
      "     bool UseZGC                                   = false                                     {product} {default}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:30.712939Z",
     "start_time": "2025-03-06T17:26:30.599546Z"
    }
   },
   "cell_type": "code",
   "source": "df_read = spark.read.parquet(\"fhvhv/2024/01\")",
   "id": "acfa6f59b0626dd1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:26:53.647045Z",
     "start_time": "2025-03-06T17:26:53.643868Z"
    }
   },
   "cell_type": "code",
   "source": "df_read.printSchema()",
   "id": "b02f863ba8245dd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp_ntz (nullable = true)\n",
      " |-- on_scene_datetime: timestamp_ntz (nullable = true)\n",
      " |-- pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can observe that `pickup_datetime`'s data type is `timestamp_ntz` which means it is a timestamp without time zone. We can convert it to a `timestamp` data type which includes time zone information. We can also convert `dropoff_datetime` to a `timestamp` data type.",
   "id": "f45e85f8b7f040bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:34:09.239265Z",
     "start_time": "2025-03-06T17:34:09.073801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# selcting columns 'pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID' where 'hvfhs_license_num' is 'HV0003'\n",
    "df_read.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID').filter(df_read.hvfhs_license_num == 'HV0003').show()"
   ],
   "id": "6218bad7903c0cee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2024-01-03 19:27:04|2024-01-03 19:35:24|          90|         114|\n",
      "|2024-01-02 22:36:17|2024-01-02 22:56:33|         138|          79|\n",
      "|2024-01-02 00:24:09|2024-01-02 00:52:53|         132|         234|\n",
      "|2024-01-01 00:21:12|2024-01-01 00:42:30|         148|         255|\n",
      "|2024-01-03 09:07:34|2024-01-03 09:13:22|         176|         172|\n",
      "|2024-01-03 16:41:02|2024-01-03 16:48:31|          26|          26|\n",
      "|2024-01-04 08:29:06|2024-01-04 08:33:12|         200|         200|\n",
      "|2024-01-02 09:14:01|2024-01-02 09:23:37|          95|         196|\n",
      "|2024-01-04 18:38:42|2024-01-04 18:45:09|         119|          69|\n",
      "|2024-01-02 17:42:43|2024-01-02 17:48:51|         242|         182|\n",
      "|2024-01-02 22:20:16|2024-01-02 22:36:59|         232|          49|\n",
      "|2024-01-04 10:17:10|2024-01-04 11:19:30|         145|         265|\n",
      "|2024-01-01 11:09:21|2024-01-01 11:18:15|         164|         231|\n",
      "|2024-01-02 19:31:10|2024-01-02 19:43:04|          95|          92|\n",
      "|2024-01-04 07:27:43|2024-01-04 07:38:23|          90|         107|\n",
      "|2024-01-02 14:17:52|2024-01-02 14:22:21|          86|          86|\n",
      "|2024-01-03 22:35:22|2024-01-03 22:53:09|         141|         116|\n",
      "|2024-01-02 07:48:47|2024-01-02 08:01:29|          56|          95|\n",
      "|2024-01-01 19:03:23|2024-01-01 19:36:04|         197|         146|\n",
      "|2024-01-02 08:25:52|2024-01-02 08:37:25|          76|          77|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T19:31:28.588707Z",
     "start_time": "2025-03-06T19:31:28.446495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_read \\\n",
    "    .withColumn('pickup_date', F.to_date('pickup_datetime')) \\\n",
    "    .withColumn('dropoff_date', F.to_date('dropoff_datetime')) \\\n",
    "    .select('pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(df_read.hvfhs_license_num == 'HV0003') \\\n",
    "    .show()"
   ],
   "id": "41cf751b1ca83ae6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+\n",
      "|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------+------------+------------+------------+\n",
      "| 2024-01-03|  2024-01-03|          90|         114|\n",
      "| 2024-01-02|  2024-01-02|         138|          79|\n",
      "| 2024-01-02|  2024-01-02|         132|         234|\n",
      "| 2024-01-01|  2024-01-01|         148|         255|\n",
      "| 2024-01-03|  2024-01-03|         176|         172|\n",
      "| 2024-01-03|  2024-01-03|          26|          26|\n",
      "| 2024-01-04|  2024-01-04|         200|         200|\n",
      "| 2024-01-02|  2024-01-02|          95|         196|\n",
      "| 2024-01-04|  2024-01-04|         119|          69|\n",
      "| 2024-01-02|  2024-01-02|         242|         182|\n",
      "| 2024-01-02|  2024-01-02|         232|          49|\n",
      "| 2024-01-04|  2024-01-04|         145|         265|\n",
      "| 2024-01-01|  2024-01-01|         164|         231|\n",
      "| 2024-01-02|  2024-01-02|          95|          92|\n",
      "| 2024-01-04|  2024-01-04|          90|         107|\n",
      "| 2024-01-02|  2024-01-02|          86|          86|\n",
      "| 2024-01-03|  2024-01-03|         141|         116|\n",
      "| 2024-01-02|  2024-01-02|          56|          95|\n",
      "| 2024-01-01|  2024-01-01|         197|         146|\n",
      "| 2024-01-02|  2024-01-02|          76|          77|\n",
      "+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T19:40:06.674633Z",
     "start_time": "2025-03-06T19:40:05.888116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a user defined function that SQL can't do\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def get_trip_duration(pickup, dropoff):\n",
    "    return str(dropoff - pickup)\n",
    "\n",
    "trip_duration_udf = F.udf(get_trip_duration, StringType())\n",
    "\n",
    "df_read \\\n",
    "    .withColumn('trip_duration', trip_duration_udf('pickup_datetime', 'dropoff_datetime')) \\\n",
    "    .select('trip_duration') \\\n",
    "    .show()"
   ],
   "id": "e7ad8005342cb52b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trip_duration|\n",
      "+-------------+\n",
      "|      0:08:20|\n",
      "|      0:20:16|\n",
      "|      0:19:16|\n",
      "|      0:28:44|\n",
      "|      0:30:18|\n",
      "|      0:21:18|\n",
      "|      0:05:48|\n",
      "|      0:07:29|\n",
      "|      0:04:06|\n",
      "|      0:26:15|\n",
      "|      0:09:36|\n",
      "|      0:06:27|\n",
      "|      0:06:08|\n",
      "|      0:14:04|\n",
      "|      0:08:57|\n",
      "|      0:21:01|\n",
      "|      0:16:43|\n",
      "|      0:03:13|\n",
      "|      1:02:20|\n",
      "|      0:20:07|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f06c7b2ab1bff89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
